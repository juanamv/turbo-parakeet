# üìÑ

Esta gu√≠a describe la configuraci√≥n de un entorno m√≠nimo usando Docker Compose para trabajar con:

- üß± **Hadoop**
- ‚ö° **Apache Spark**
- ‚òï **Java**
- üêç **Python**
- üìì **Jupyter Notebook**

---

## üß≠ √çndice

- [üìå Descripci√≥n General](#-descripci√≥n-general)
- [üîß Servicios y Configuraci√≥n](#-servicios-y-configuraci√≥n)
  - [üß± Hadoop](#-hadoop)
  - [‚ö° Apache Spark](#-apache-spark)
  - [üìì Jupyter Notebook y PySpark](#-jupyter-notebook-y-pyspark)
- [üíæ Vol√∫menes](#-vol√∫menes)
- [üöÄ Instrucciones de Uso](#-instrucciones-de-uso)

---

## üìå Descripci√≥n General

Este entorno contiene servicios esenciales para ejecutar y experimentar con procesamiento distribuido de datos. Est√° dise√±ado para funcionar localmente con el m√≠nimo de configuraci√≥n extra.

---

## üîß Servicios y Configuraci√≥n

### üß± Hadoop

| Servicio        | Imagen                                                                   | Puerto(s)        | Descripci√≥n                              |
|----------------|--------------------------------------------------------------------------|------------------|------------------------------------------|
| **namenode**    | `bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8`                         | `9870`, `9000`   | UI del HDFS y punto de acceso HDFS       |
| **datanode**    | `bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8`                         | ‚Äî                | Almac√©n de datos                         |
| **resourcemanager** | `bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8`              | `8088`           | UI de YARN ResourceManager               |
| **nodemanager** | `bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8`                      | ‚Äî                | Gesti√≥n de recursos en los nodos         |

---

### ‚ö° Apache Spark

| Servicio        | Imagen                                         | Puerto(s)       | Descripci√≥n                       |
|----------------|-----------------------------------------------|-----------------|-----------------------------------|
| **spark-master** | `bde2020/spark-master:3.0.0-hadoop3.2`        | `8080`, `7077`  | Coordinador del cl√∫ster de Spark |
| **spark-worker** | `bde2020/spark-worker:3.0.0-hadoop3.2`        | `8081`          | Nodo de ejecuci√≥n de Spark       |

---

### üìì Jupyter Notebook y PySpark

| Servicio    | Imagen                               | Puerto(s)         | Volumen                              |
|-------------|--------------------------------------|-------------------|--------------------------------------|
| **jupyter** | `jupyter/pyspark-notebook:latest`    | `8888`, `4040`    | `./notebooks:/home/jovyan/work`     |

- `8888`: Interfaz de Jupyter Lab / Notebook  
- `4040`: UI del Spark Driver (cuando se ejecuta un job)

---

## üíæ Vol√∫menes

| Nombre            | Usado por     | Ruta interna                        |
|-------------------|---------------|-------------------------------------|
| `hadoop_namenode` | namenode      | `/hadoop/dfs/name`                  |
| `hadoop_datanode` | datanode      | `/hadoop/dfs/data`                  |

---

## üöÄ Instrucciones de Uso

### ‚úÖ Requisitos

- Tener instalado:
  - Docker
  - Docker Compose
- Acceso a internet (para descargar las im√°genes)

---

### ‚ñ∂Ô∏è Paso a Paso

1. Abre una terminal en el directorio del archivo `docker-compose.yml`.
2. Inicia el entorno:

   ```bash
   docker-compose up -d
   ```

3. Accede a los servicios en tu navegador:

| Servicio          | URL                                 |
|-------------------|--------------------------------------|
| HDFS (NameNode UI) | [http://localhost:9870](http://localhost:9870) |
| YARN UI           | [http://localhost:8088](http://localhost:8088) |
| Spark Master UI   | [http://localhost:8080](http://localhost:8080) |
| Spark Worker UI   | [http://localhost:8081](http://localhost:8081) |
| Jupyter Notebook  | [http://localhost:8888](http://localhost:8888) |

> üí° El puerto `4040` se activa autom√°ticamente al ejecutar un trabajo Spark desde Jupyter.

---

### üõë Para detener todo

```bash
docker-compose down
```

---

## üìù Notas Finales

- Las im√°genes de Hadoop y Spark ya incluyen **Java**, no necesitas instalar nada adicional.
- El contenedor `jupyter` ya viene con **Python**, **Spark** y **Jupyter Lab** listos para usar.
- Esta configuraci√≥n est√° pensada para entornos de desarrollo y pruebas locales.
- Para obtener el **token** de jupyter consulta los logs del servicio de `jupyter notebook`

---

**Documentaci√≥n generada autom√°ticamente** ü§ñ
> ‚ö†Ô∏è *Esta documentaci√≥n fue generada autom√°ticamente. Verifica su contenido antes de usarlo.*
